{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31a4484c",
   "metadata": {
    "raw_mimetype": "text/x-python",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# ***       Parameters cell        ***\n",
    "# *** Used to automate experiments ***\n",
    "\n",
    "# View > Cell Toolbar > Tags: set the tag as \"parameters\"\n",
    "\n",
    "p = 8000 #2000        # Default value\n",
    "n_ = 63 #  40          # Default value # Not the real n! Real n defined below...\n",
    "percent = 0.75 # 1.25  # Default value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d8045",
   "metadata": {},
   "source": [
    "# Genetic Application: Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef74b63-fdd4-4be0-958c-efc67f569d18",
   "metadata": {},
   "source": [
    "## Intro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0196a-968a-4ce2-94cf-7b1d8d9fb11a",
   "metadata": {},
   "source": [
    "- We consider $n$ samples for **few-shot learning**\n",
    "- The matrix $\\mathbf{X}$ now consists of $n$ samples of size $p = 7129$, with $n << p$.\n",
    "- The vector $\\mathbf{y}$ consists of the $n$ labels of $\\mathbf{X}$ (i.e. $y_i \\in \\{-1, +1\\}$ for all $i = 1,\\dots,n$)\n",
    "- We consider the following **feature selection** task: learn a **sparse set of explainable features** (i.e. pixels) $\\boldsymbol{\\hat \\beta}$ from which a small set of training samples samples $\\mathbf{X}, \\mathbf{y}$ can be classified as gppd as possible. Formally,\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{minimize}_{\\boldsymbol{\\beta} \\in \\mathbb{B}^p} && \\| \\mathbf{X} \\boldsymbol{\\beta} - \\mathbf{y} \\|^2_2 \\\\\n",
    "\\text{subject to} && \\| \\boldsymbol{\\beta} \\|_1 \\leq \\eta\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and $\\mathbf{y} \\in \\{-1, +1\\}^{n}$ are the few training samples and labels, respectively (with $n << p$), and $\\eta$ is the number of explainable features to be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672002b",
   "metadata": {},
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80c00e25-d4df-4d14-9759-4c8fce74ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplake\n",
    "# !pip install -U scikit-learn\n",
    "\n",
    "# !pip install fcbf\n",
    "# # https://github.com/m-martin-j/fcbf\n",
    "\n",
    "# # --- For automated experiments --- #\n",
    "# !pip install papermill\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3737a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "#import deeplake\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from fcbf import fcbf, data\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, r_regression, chi2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from utils.utils import *\n",
    "from utils.models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d36c0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f029b1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ace7767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters cell must be the first cell of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "891155a3-1162-4e50-b202-8edbdb96b1f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of selected features N_z:\t60\n",
      "Number of observations n:\t\t126\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = p // n_    # redefine n\n",
    "nb_fts = int(p * percent // 100)\n",
    "\n",
    "print(f\"Number of selected features N_z:\\t{nb_fts}\")\n",
    "print(f\"Number of observations n:\\t\\t{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e2abc297-6d64-4d5b-b3ad-b619b58ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.path.join( f\"results/synthetic_data_{p}\" ) # separate folders for different p\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "\n",
    "results_folder = os.path.join( results_folder, f\"{n}\" )  # separate folders for different n\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "    \n",
    "results_folder = os.path.join( results_folder, f\"{nb_fts}\" )  # separate folders for different nb_fts\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ff1f3-afb1-43c3-917b-2218ac1cbca4",
   "metadata": {},
   "source": [
    "## Models and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c7b5c51-7a22-4ce9-8392-37225718479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your models\n",
    "\n",
    "models_l = [\"knn\", \n",
    "            \"lr\", \n",
    "            \"svc\", \n",
    "            \"nb-gaussian\", \n",
    "            ### \"nb-bernouilli\", \n",
    "            ### \"nb-categorical\",\n",
    "            ### \"rf\"\n",
    "           ]\n",
    "\n",
    "# Choose your feature selection methods\n",
    "fts_modes_l = [\"full\", \n",
    "               \"random\", \n",
    "               \"k-best\", \n",
    "               #\"k-best-mi\", # XXX\n",
    "               ###\"pca\", \n",
    "               # \"sparse-pca\",  # takes huge time...\n",
    "               ###\"lfs\", \n",
    "               ###\"lbs\", \n",
    "               ###\"fcbf\"        # do it one time, since always the same\n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef7817-1f26-4d4b-ba7d-f45ebc2e21f8",
   "metadata": {},
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "106ec0c8-3cc9-42d0-ae8e-55da1b688771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** NEW ***\n",
    "\n",
    "# Parameters\n",
    "n_features = p          # Total number of features\n",
    "n_observations = n      # Number of samples (rows)\n",
    "n_informative = nb_fts  # Number of informative (relevant) features\n",
    "\n",
    "# Seed for reproducibility\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Generate the synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=n_observations,\n",
    "    n_features=n_features,\n",
    "    n_informative=n_informative,\n",
    "    n_redundant=0,          # No redundant features\n",
    "    n_repeated=0,           # No repeated features\n",
    "    n_classes=2,            # Binary classification\n",
    "    n_clusters_per_class=1, # Single cluster per class\n",
    "    weights=None,           # Balanced classes\n",
    "    flip_y=0.0,             # No noise to the labels (default 0.01)\n",
    "    class_sep=1.0,          # Separation between the classes\n",
    "    shuffle=True,           # if False, informative features first. True improves the results! # XXX\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fts_index = list(range(0, n_informative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e67d456e-e50f-49bf-a364-bf024ef8145a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((126, 8000), (126,))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = X\n",
    "data.shape, y.shape\n",
    "# fts_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "260ff814",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
       "       0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d45637-f0ef-4bdd-8917-c1b7a301e335",
   "metadata": {},
   "source": [
    "## Ten times 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2df87ffb-1eda-4bdd-ae04-00fa6ae75255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_splits(data=data, seed=42):\n",
    "\n",
    "    cv_d = {\"train_splits\": [], \"test_splits\": []}\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    kf.get_n_splits(data)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "\n",
    "        cv_d[\"train_splits\"].append(train_index)\n",
    "        cv_d[\"test_splits\"].append(test_index)\n",
    "        \n",
    "    return cv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8feda798-03cb-491f-abf0-d7c53ff788a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_d = get_CV_splits(data=data, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7060137a-323a-482c-90cf-1fe155f4a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 2203.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# 10 times 10-fold CV\n",
    "\n",
    "cv_splits_all = []\n",
    "\n",
    "for seed in tqdm([33, 42, 1, 5, 1979, 2024, 22, 12, 1996, 11]):\n",
    "    \n",
    "    cv_d = get_CV_splits(data, seed=seed)\n",
    "    \n",
    "    cv_splits_all.append(cv_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8217b7be-7085-438f-b605-73a309d871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_splits_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aaedabed-547e-46f1-b6ac-39de62910bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # *** Uncomment and debug this for the case `shuffle=True` ***\n",
    "# # *** in the `make_classification` function                ***\n",
    "\n",
    "# def get_percentage_retreived_fts(fts_mode, X, y, fts_index=fts_index):\n",
    "#     \"\"\"Gets the percentage of retrieved features.\"\"\"\n",
    "    \n",
    "#     # sparse-pca\n",
    "#     if isinstance(fts_mode, sklearn.decomposition._sparse_pca.SparsePCA):\n",
    "        \n",
    "#         # select fts with largest weights\n",
    "#         selected_fts = fts_mode.components_\n",
    "#         selected_fts = set(np.argmax(selected_fts, axis=1))\n",
    "    \n",
    "#     # k-best and k-best-mi\n",
    "#     elif isinstance(fts_mode, sklearn.feature_selection._univariate_selection.SelectKBest):\n",
    "        \n",
    "#         # select fts with largest scores\n",
    "#         # for k-best\n",
    "#         if fts_mode.score_func == sklearn.feature_selection._univariate_selection.f_classif:\n",
    "#             scores = fts_mode.get_params()[\"score_func\"](X, y)[0]\n",
    "            \n",
    "#         # for k-best-mi  \n",
    "#         elif fts_mode.score_func == sklearn.feature_selection._mutual_info.mutual_info_classif:\n",
    "#             scores = fts_mode.get_params()[\"score_func\"](X, y)\n",
    "            \n",
    "#         scores_tmp = scores.copy()\n",
    "#         scores_tmp.sort()\n",
    "#         max_scores = scores_tmp[-nb_fts:]\n",
    "#         selected_fts = [np.where(scores == x)[0].item() for x in max_scores] # one-liner\n",
    "    \n",
    "#     intersection = set(selected_fts).intersection(set(fts_index))\n",
    "#     retreived_fts_p = len(intersection) / len(fts_index)\n",
    "\n",
    "#     return retreived_fts_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d4518fa9-7df4-47bf-94fe-dfde9996f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def select_features(train_indices, test_indices, data=data, y=y, \n",
    "                    norm=True, fts_mode=\"full\", fts_index=fts_index):\n",
    "\n",
    "    # 2. fts selection\n",
    "    if fts_mode == \"random\":\n",
    "        rand_ind = np.random.randint(low=0, high=data.shape[1], size=nb_fts, dtype=int)\n",
    "        current_data = data[:, rand_ind]\n",
    "\n",
    "        # percentage of retreiveed features\n",
    "        intersection = set(rand_ind).intersection(set(fts_index))\n",
    "        retreived_fts_p = len(intersection) / len(fts_index)\n",
    "\n",
    "    else:\n",
    "        current_data = data\n",
    "        retreived_fts_p = 0.  # dummy value for \"full\" mode\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_split = label_encoder.fit_transform(y_train_split)\n",
    "    y_train_split = 2 * y_train_split - 1               # rescale targets in {-1, +1}\n",
    "    \n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = label_encoder.transform(y_test_split)\n",
    "    y_test_split = 2 * y_test_split - 1                 # rescale targets in {-1, +1}\n",
    "\n",
    "    if fts_mode == \"pca\": # unsupervised\n",
    "        pca = PCA(n_components=min(nb_fts, len(X_train_split))) # PCA limited by nb of rows of X (64)\n",
    "        X_train_split = pca.fit_transform(X_train_split)\n",
    "        X_test_split = pca.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"sparse-pca\": # unsupervised\n",
    "        sparse_pca = SparsePCA(n_components=nb_fts, alpha=0.5, tol=1e-4, verbose=False)\n",
    "        X_train_split = sparse_pca.fit_transform(X_train_split)\n",
    "        X_test_split = sparse_pca.transform(X_test_split)\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(sparse_pca, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index) # new\n",
    "\n",
    "        retreived_fts_p = 0.\n",
    "\n",
    "\n",
    "    if fts_mode == \"lfs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"forward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"lbs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"backward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"k-best\": # supervised\n",
    "        # k_best = SelectKBest(chi2, k=nb_fts)\n",
    "        k_best = SelectKBest(f_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "        \n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "    \n",
    "\n",
    "    if fts_mode == \"k-best-mi\": # supervised\n",
    "        k_best = SelectKBest(mutual_info_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"fcbf\": # supervised\n",
    "        X_train_split_df = pd.DataFrame(X_train_split)\n",
    "        X_test_split_df = pd.DataFrame(X_test_split)\n",
    "        y_train_split_df = pd.Series(y_train_split).astype(int)\n",
    "\n",
    "        nb_cols = X_train\n",
    "        _split.shape[1] + 1\n",
    "        dataset = pd.concat([X_train_split_df, y_train_split_df], axis=1)\n",
    "        dataset.columns = list(range(nb_cols))\n",
    "        X_train_split_df = dataset.iloc[:, :-1]\n",
    "        y_train_split_df = dataset.iloc[:, -1].astype(int)\n",
    "        \n",
    "        fts_ind, _, _ = fcbf(X_train_split_df, y_train_split_df, su_threshold=0.1, base=2)\n",
    "        print(\"Selected features\", fts_ind)       # only one feature selected whatever the threshold???\n",
    "        X_train_split = X_train_split[:, fts_ind]\n",
    "        X_test_split = X_test_split[:, fts_ind]\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    return X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0c4089ad-f8e9-4e13-8a8a-0185ec66a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def fit_model(X_train_split, y_train_split, X_test_split, y_test_split, model=\"knn\"):\n",
    "    \n",
    "    # 1. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "        \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb06472-c9d5-4011-a3d6-9dc05c174a52",
   "metadata": {},
   "source": [
    "## All experiments except Pk-LPNN at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc1ca3-9655-4f0f-a4d2-eae86313d981",
   "metadata": {},
   "source": [
    "> - The following cell runs all feature selection modes (`fts_modes_l`) and all dowstream models (`models_l`).\n",
    "> \n",
    "> - The results are then saved in `results_folder/`.\n",
    ">\n",
    "> - Hence, the individual sections (Full features, Random features, etc.) do not need to be executed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc09b4bc-df14-426e-9d0f-5d168b32bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:10<00:00,  1.07s/it]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:01<00:00,  5.84it/s]\n",
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:03<00:00,  2.80it/s]\n"
     ]
    }
   ],
   "source": [
    "# *** new loop ***\n",
    "# 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_all_d = {}\n",
    "\n",
    "# 1. loop over feat modes:\n",
    "for fts_mode in fts_modes_l:\n",
    "        \n",
    "    results_all_d[fts_mode] = {}\n",
    "\n",
    "    # 2. 10 times 10-fold CV: 100 experiments\n",
    "    for cv_d in tqdm(cv_splits_all):\n",
    "        for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "        \n",
    "            X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p = select_features(train_indices, \n",
    "                                                                                                        test_indices,\n",
    "                                                                                                        data=data,\n",
    "                                                                                                        y=y,\n",
    "                                                                                                        norm=False, # xxx\n",
    "                                                                                                        fts_mode=fts_mode)       \n",
    "            # 3. loop over models\n",
    "            for model in models_l:\n",
    "    \n",
    "                if model not in results_all_d[fts_mode].keys():\n",
    "                    results_all_d[fts_mode][model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "                \n",
    "                f1, b_acc = fit_model(X_train_split, \n",
    "                                      y_train_split, \n",
    "                                      X_test_split, \n",
    "                                      y_test_split, \n",
    "                                      model=model)\n",
    "                \n",
    "                results_all_d[fts_mode][model][\"f1\"].append(f1)\n",
    "                results_all_d[fts_mode][model][\"b_acc\"].append(b_acc)\n",
    "                results_all_d[fts_mode][model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    # save all results for fts_mode\n",
    "    for model in models_l:\n",
    "        \n",
    "        with open(os.path.join(results_folder, f\"{fts_mode}_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "            pickle.dump(results_all_d[fts_mode][model], fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "16bb5a3f-67a7-46de-a471-8e35924d4835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "*** Features mode: full - Model: knn ***\n",
      "Test: macro F1 (mean, std): \t\t0.8505012454865397\n",
      "Test: balanced accuracy (mean, std): \t0.8690871212121213\n",
      "************************************************************\n",
      "*** Features mode: full - Model: lr ***\n",
      "Test: macro F1 (mean, std): \t\t0.8287126917630013\n",
      "Test: balanced accuracy (mean, std): \t0.8429280303030304\n",
      "************************************************************\n",
      "*** Features mode: full - Model: svc ***\n",
      "Test: macro F1 (mean, std): \t\t0.7246005024387376\n",
      "Test: balanced accuracy (mean, std): \t0.7752074314574315\n",
      "************************************************************\n",
      "*** Features mode: full - Model: nb-gaussian ***\n",
      "Test: macro F1 (mean, std): \t\t0.4657757626360567\n",
      "Test: balanced accuracy (mean, std): \t0.5215842352092352\n",
      "************************************************************\n",
      "*** Features mode: random - Model: knn ***\n",
      "Test: macro F1 (mean, std): \t\t0.4862052776944419\n",
      "Test: balanced accuracy (mean, std): \t0.5152575757575757\n",
      "************************************************************\n",
      "*** Features mode: random - Model: lr ***\n",
      "Test: macro F1 (mean, std): \t\t0.4885068924024033\n",
      "Test: balanced accuracy (mean, std): \t0.5046468253968254\n",
      "************************************************************\n",
      "*** Features mode: random - Model: svc ***\n",
      "Test: macro F1 (mean, std): \t\t0.4686903766168472\n",
      "Test: balanced accuracy (mean, std): \t0.5025330086580088\n",
      "************************************************************\n",
      "*** Features mode: random - Model: nb-gaussian ***\n",
      "Test: macro F1 (mean, std): \t\t0.46534458364992426\n",
      "Test: balanced accuracy (mean, std): \t0.48314448051948056\n",
      "************************************************************\n",
      "*** Features mode: k-best - Model: knn ***\n",
      "Test: macro F1 (mean, std): \t\t0.6577120721350262\n",
      "Test: balanced accuracy (mean, std): \t0.6838739177489178\n",
      "************************************************************\n",
      "*** Features mode: k-best - Model: lr ***\n",
      "Test: macro F1 (mean, std): \t\t0.6443526457202928\n",
      "Test: balanced accuracy (mean, std): \t0.6585618686868685\n",
      "************************************************************\n",
      "*** Features mode: k-best - Model: svc ***\n",
      "Test: macro F1 (mean, std): \t\t0.6912585713220387\n",
      "Test: balanced accuracy (mean, std): \t0.7115586219336216\n",
      "************************************************************\n",
      "*** Features mode: k-best - Model: nb-gaussian ***\n",
      "Test: macro F1 (mean, std): \t\t0.6314530094088917\n",
      "Test: balanced accuracy (mean, std): \t0.6494386724386725\n"
     ]
    }
   ],
   "source": [
    "for fts_mode in fts_modes_l:\n",
    "\n",
    "    for model in models_l:\n",
    "        print(\"*\"*60)\n",
    "        \n",
    "        scores_full_fts = results_all_d[fts_mode][model]\n",
    "    \n",
    "        print(f\"*** Features mode: {fts_mode} - Model: {model} ***\")\n",
    "        print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(scores_full_fts[\"f1\"])}\"\"\")\n",
    "        print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(scores_full_fts[\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8817b07-aea7-4ee1-9d82-d142e17bb266",
   "metadata": {},
   "source": [
    "> **STOP**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881f9fb",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Pk-LPNN-selected features (normalized)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427679c1-1f03-4fbe-9c07-68f3683064c1",
   "metadata": {},
   "source": [
    "> - This is the code for the Pk-LPNN experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "617088a3-f676-488a-83b9-937d6f86bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 10 times:\n",
    "#   10-fold CV\n",
    "#   train PK-LPNN on 9 folds                     -> Nz selected fts\n",
    "#   test PK-LPNN on 1 fold (KNN + selected fts)  -> b_acc, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c5ab2116",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables deleted...\n"
     ]
    }
   ],
   "source": [
    "# Security...\n",
    "\n",
    "try:\n",
    "    del X_train_split\n",
    "    del y_train_split\n",
    "    del X_test_split\n",
    "    del y_test_split\n",
    "    del f1\n",
    "    del b_acc\n",
    "    print(\"Variables deleted...\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ff93a60f-8e5a-42af-a9d6-3294035ddad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPNN_experiment(X_train_split, y_train_split,\n",
    "                    p, Nz, k, mu_0=0.5, train_indices=None):\n",
    "\n",
    "    # 1. normalize (here and not later!)\n",
    "    X_train_split = normalize(X_train_split, axis=0)\n",
    "    \n",
    "    # 2. Initialization\n",
    "    beta_0, mu_0 = beta_0_and_mu_0(p=p, Nz=Nz, k=k, mu_0=mu_0, method=\"Pk-LPNN_v2\")\n",
    "    # check_conditions(beta, X, beta_0, n, Nz, k, method=method)\n",
    "\n",
    "    # 3. dynamical system\n",
    "    z0 = np.hstack([beta_0, mu_0])\n",
    "    t_span = (0, 30) # (0, 30)\n",
    "    t = t_span[1]\n",
    "    eta = Nz\n",
    "\n",
    "    # with tqdm() as pbar: # too much printing\n",
    "        \n",
    "    sol = solve_ivp(LPNN, \n",
    "                    t_span=t_span, \n",
    "                    y0=z0, \n",
    "                    args=(X_train_split, y_train_split, eta, k, \"Pk-LPNN_v2\"), #, pbar),\n",
    "                    method=\"RK45\", # DOP853, RK45\n",
    "                    dense_output=False, \n",
    "                    max_step=0.1, \n",
    "                    atol=1.2e-4, \n",
    "                    rtol=1e-4)\n",
    "\n",
    "    beta_sol = sol[\"y\"][:-1, -1]\n",
    "    mu_sol = sol[\"y\"][-1, -1]\n",
    "\n",
    "    selected_ind = np.argpartition(np.abs(beta_sol), -Nz)[-Nz:]\n",
    "    \n",
    "    return list(selected_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43c75e9d-02ef-437b-abde-f4d5f3274b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single experiment for selected features\n",
    "\n",
    "def downstream_models(data=data, y=y, norm=True,\n",
    "               train_indices=None, test_indices=None, selected_ind=None, \n",
    "               model=\"knn\"):\n",
    "    \n",
    "    # 1. fts selection    \n",
    "    current_data = data[:, selected_ind]\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "    y_train_split = 2 * y_train_split - 1                        # rescale targets in {-1, +1}\n",
    "\n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = 2 * y_test_split - 1                          # rescale targets in {-1, +1}\n",
    "\n",
    "    # 3. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "    \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fae0e91f-9119-49f2-b23b-4006877fbcd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:38, 158.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 1 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "2it [05:23, 162.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 2 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "3it [07:56, 157.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 3 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "4it [10:29, 156.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 4 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "5it [12:57, 153.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 5 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "6it [15:26, 151.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 6 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "7it [17:55, 150.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 7 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "8it [20:24, 150.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 8 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "9it [22:59, 151.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 9 finished for all models.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [25:26, 152.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV 10 finished for all models.\n",
      "*** Features mode: Pk-LPNN - Model: knn ***\n",
      "Test: macro F1 (mean, std): \t\t0.6279194956660127\n",
      "Test: balanced accuracy (mean, std): \t0.6516280663780664\n",
      "*** Features mode: Pk-LPNN - Model: lr ***\n",
      "Test: macro F1 (mean, std): \t\t0.6030572139418888\n",
      "Test: balanced accuracy (mean, std): \t0.6218993506493506\n",
      "*** Features mode: Pk-LPNN - Model: svc ***\n",
      "Test: macro F1 (mean, std): \t\t0.6317216250381885\n",
      "Test: balanced accuracy (mean, std): \t0.6568495670995671\n",
      "*** Features mode: Pk-LPNN - Model: nb-gaussian ***\n",
      "Test: macro F1 (mean, std): \t\t0.5902101535375529\n",
      "Test: balanced accuracy (mean, std): \t0.6069330808080808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# All experiments: 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_d = {}\n",
    "\n",
    "for i, cv_d in tqdm(enumerate(cv_splits_all)):\n",
    "\n",
    "    for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "            \n",
    "        # train set\n",
    "        X_train_split = data[train_indices, :]\n",
    "        y_train_split = y[train_indices]\n",
    "        y_train_split = 2 * y_train_split - 1        # rescale targets in {-1, +1}\n",
    "\n",
    "        # parameters\n",
    "        k = 1000     # check effect of k\n",
    "        Nz = nb_fts  # i.e. 178 Nz_l[0]\n",
    "        # sigma = 0.02  # useless here, no noise\n",
    "        mu_0 = 0.5\n",
    "\n",
    "        # Pk-LPNN ft selection\n",
    "        selected_ind = LPNN_experiment(X_train_split, y_train_split,\n",
    "                                       p, Nz, k, mu_0=0.5, train_indices=train_indices)\n",
    "        \n",
    "        true_cap_retreived_fts = set(selected_ind).intersection(set(fts_index))\n",
    "        retreived_fts_p = len(true_cap_retreived_fts) / nb_fts\n",
    "                \n",
    "        # model with selected fts\n",
    "        for model in models_l:\n",
    "\n",
    "            if model not in results_d: # create dict if not exists\n",
    "                results_d[model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "            \n",
    "            f1, b_acc = downstream_models(data=data, y=y,\n",
    "                                          norm=False, # xxx \n",
    "                                          train_indices=train_indices, \n",
    "                                          test_indices=test_indices, \n",
    "                                          selected_ind=selected_ind, \n",
    "                                          model=model)\n",
    "                        \n",
    "            results_d[model][\"f1\"].append(f1)\n",
    "            results_d[model][\"b_acc\"].append(b_acc)\n",
    "            results_d[model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    print(f\"CV {i+1} finished for all models.\")\n",
    "    \n",
    "\n",
    "# save results\n",
    "for model in models_l:\n",
    "    \n",
    "    with open(os.path.join(results_folder, f\"pk-lpnn_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "        pickle.dump(results_d[model], fh)\n",
    "\n",
    "    print(f\"*** Features mode: Pk-LPNN - Model: {model} ***\")\n",
    "    print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(results_d[model][\"f1\"])}\"\"\")\n",
    "    print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(results_d[model][\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebd0a0e-b154-4b0c-835c-870b8afb3f20",
   "metadata": {},
   "source": [
    "> **TO DO**\n",
    "> - Get percentage of retreived features for\n",
    ">   - ✅ `Pk-LPNN`\n",
    ">   - ✅ `sparse-pca`\n",
    ">   - ✅ `k-best`\n",
    ">   - ✅ `k-best-mi`\n",
    ">   - ✅ `random`\n",
    "> - ✅ Add these to the resutls\n",
    "> - Automate experiments\n",
    "> - Run experiments\n",
    ">   - `p = 2000` : `percent = 1.25%, 2.5%, 5%, 10%` / `n_ = 100, 40, 20` => `n = 20,  50,  100`\n",
    ">   - `p = 4000` : `percent = 1.25%, 2.5%, 5%, 10%` / `n_ = 100, 40, 20` => `n = 40,  100, 200`\n",
    ">   - `p = 6000` : `percent = 1.25%, 2.5%, 5%, 10%` / `n_ = 100, 40, 20` => `n = 60,  150, 300`\n",
    ">   - `p = 8000` : `percent = 1.25%, 2.5%, 5%, 10%` / `n_ = 100, 40, 20` => `n = 80,  200, 400`\n",
    ">   - `p = 10000`: `percent = 1.25%, 2.5%, 5%, 10%` / `n_ = 100, 40, 20` => `n = 100, 250, 500`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5e7ae7-d9ea-4951-9a19-372b23f3b158",
   "metadata": {},
   "source": [
    "**Remarks**\n",
    "1. Rescaling targets between -1 and +1 does not affect classical feature selection methods but drastically improves Pk-LPNN. Hence, we adopt the rescaling targets schemes.\n",
    "2. Normalizing data decreases the results! We don't normalize now. But we still normalize in `LPNN_experiment` function.\n",
    "3. In `make_classification`, setting `shuffle = True` drastically improves the results of Pk-LPNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f37fa72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6656f43c",
   "metadata": {},
   "source": [
    "**Troubleshooting:**\n",
    "- Le problème venait de la seed! La fonction `LPNN_experiment` appelle `beta_0_and_mu_0` de `models/` qui utilise de l'aléatoire (`np.random`). En ajoutant/supprimant/ré-exécutant des cellules du notebook, le fontionnement de `beta_0_and_mu_0` est moodifié, et donc les résultats également."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b61e29",
   "metadata": {},
   "source": [
    "**Remarque**\n",
    "- Tester avec $N_z \\in \\{ 0.75\\%, 1.00\\%, 1.25\\% \\}$ et $n \\simeq N_z \\cdot \\log(\\frac{p}{N_z})$\n",
    "-Se comparer à `k-best` et `k-best-mi` et pas à `full-fts` (qui est excellent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2132aab8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "base_env",
   "language": "python",
   "name": "base_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
