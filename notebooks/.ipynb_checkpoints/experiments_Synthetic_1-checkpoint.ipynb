{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a4484c",
   "metadata": {
    "raw_mimetype": "text/x-python",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# ***       Parameters cell        ***\n",
    "# *** Used to automate experiments ***\n",
    "\n",
    "# View > Cell Toolbar > Tags: set the tag as \"parameters\"\n",
    "\n",
    "p = 8000 #2000        # Default value\n",
    "n_ = 63 #  40          # Default value # Not the real n! Real n defined below...\n",
    "percent = 0.75 # 1.25  # Default value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d8045",
   "metadata": {},
   "source": [
    "# Genetic Application: Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672002b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c00e25-d4df-4d14-9759-4c8fce74ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplake\n",
    "# !pip install -U scikit-learn\n",
    "\n",
    "# # --- For automated experiments --- #\n",
    "# !pip install papermill\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9726c51-d30f-440a-86dc-9745873c32a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "#import deeplake\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, r_regression, chi2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f029b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ace7767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters cell must be the first cell of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891155a3-1162-4e50-b202-8edbdb96b1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n = p // n_    # redefine n\n",
    "nb_fts = int(p * percent // 100)\n",
    "\n",
    "print(f\"Number of selected features N_z:\\t{nb_fts}\")\n",
    "print(f\"Number of observations n:\\t\\t{n}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abc297-6d64-4d5b-b3ad-b619b58ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.path.join( f\"results/synthetic_data_{p}\" ) # separate folders for different p\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "\n",
    "results_folder = os.path.join( results_folder, f\"{n}\" )  # separate folders for different n\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "    \n",
    "results_folder = os.path.join( results_folder, f\"{nb_fts}\" )  # separate folders for different nb_fts\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ff1f3-afb1-43c3-917b-2218ac1cbca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Models and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7b5c51-7a22-4ce9-8392-37225718479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your models\n",
    "\n",
    "models_l = [\"knn\", \n",
    "            \"lr\", \n",
    "            \"svc\", \n",
    "            \"nb-gaussian\", \n",
    "            ### \"nb-bernouilli\", \n",
    "            ### \"nb-categorical\",\n",
    "            ### \"rf\"\n",
    "           ]\n",
    "\n",
    "# Choose your feature selection methods\n",
    "fts_modes_l = [\"full\", \n",
    "               \"random\", \n",
    "               \"k-best\", \n",
    "               #\"k-best-mi\",\n",
    "               ###\"pca\", \n",
    "               # \"sparse-pca\",  # takes huge time...\n",
    "               ###\"lfs\", \n",
    "               ###\"lbs\", \n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef7817-1f26-4d4b-ba7d-f45ebc2e21f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106ec0c8-3cc9-42d0-ae8e-55da1b688771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** NEW ***\n",
    "\n",
    "# Parameters\n",
    "n_features = p          # Total number of features\n",
    "n_observations = n      # Number of samples (rows)\n",
    "n_informative = nb_fts  # Number of informative (relevant) features\n",
    "\n",
    "# Seed for reproducibility\n",
    "#np.random.seed(42)\n",
    "\n",
    "# Generate the synthetic dataset\n",
    "X, y = make_classification(\n",
    "    n_samples=n_observations,\n",
    "    n_features=n_features,\n",
    "    n_informative=n_informative,\n",
    "    n_redundant=0,          # No redundant features\n",
    "    n_repeated=0,           # No repeated features\n",
    "    n_classes=2,            # Binary classification\n",
    "    n_clusters_per_class=1, # Single cluster per class\n",
    "    weights=None,           # Balanced classes\n",
    "    flip_y=0.0,             # No noise to the labels (default 0.01)\n",
    "    class_sep=1.0,          # Separation between the classes\n",
    "    shuffle=True,           # if False, informative features first. True improves the results! # XXX\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "fts_index = list(range(0, n_informative))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67d456e-e50f-49bf-a364-bf024ef8145a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = X\n",
    "data.shape, y.shape\n",
    "# fts_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260ff814",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d45637-f0ef-4bdd-8917-c1b7a301e335",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ten times 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df87ffb-1eda-4bdd-ae04-00fa6ae75255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_splits(data=data, seed=42):\n",
    "\n",
    "    cv_d = {\"train_splits\": [], \"test_splits\": []}\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    kf.get_n_splits(data)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "\n",
    "        cv_d[\"train_splits\"].append(train_index)\n",
    "        cv_d[\"test_splits\"].append(test_index)\n",
    "        \n",
    "    return cv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feda798-03cb-491f-abf0-d7c53ff788a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_d = get_CV_splits(data=data, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060137a-323a-482c-90cf-1fe155f4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 times 10-fold CV\n",
    "\n",
    "cv_splits_all = []\n",
    "\n",
    "for seed in tqdm([33, 42, 1, 5, 1979, 2024, 22, 12, 1996, 11]):\n",
    "    \n",
    "    cv_d = get_CV_splits(data, seed=seed)\n",
    "    \n",
    "    cv_splits_all.append(cv_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217b7be-7085-438f-b605-73a309d871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_splits_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4518fa9-7df4-47bf-94fe-dfde9996f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def select_features(train_indices, test_indices, data=data, y=y, \n",
    "                    norm=True, fts_mode=\"full\", fts_index=fts_index):\n",
    "\n",
    "    # 2. fts selection\n",
    "    if fts_mode == \"random\":\n",
    "        rand_ind = np.random.randint(low=0, high=data.shape[1], size=nb_fts, dtype=int)\n",
    "        current_data = data[:, rand_ind]\n",
    "\n",
    "        # percentage of retreiveed features\n",
    "        intersection = set(rand_ind).intersection(set(fts_index))\n",
    "        retreived_fts_p = len(intersection) / len(fts_index)\n",
    "\n",
    "    else:\n",
    "        current_data = data\n",
    "        retreived_fts_p = 0.  # dummy value for \"full\" mode\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_split = label_encoder.fit_transform(y_train_split)\n",
    "    y_train_split = 2 * y_train_split - 1               # rescale targets in {-1, +1}\n",
    "    \n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = label_encoder.transform(y_test_split)\n",
    "    y_test_split = 2 * y_test_split - 1                 # rescale targets in {-1, +1}\n",
    "\n",
    "    if fts_mode == \"pca\": # unsupervised\n",
    "        pca = PCA(n_components=min(nb_fts, len(X_train_split))) # PCA limited by nb of rows of X (64)\n",
    "        X_train_split = pca.fit_transform(X_train_split)\n",
    "        X_test_split = pca.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"sparse-pca\": # unsupervised\n",
    "        sparse_pca = SparsePCA(n_components=nb_fts, alpha=0.5, tol=1e-4, verbose=False)\n",
    "        X_train_split = sparse_pca.fit_transform(X_train_split)\n",
    "        X_test_split = sparse_pca.transform(X_test_split)\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(sparse_pca, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index) # new\n",
    "\n",
    "        retreived_fts_p = 0.\n",
    "\n",
    "\n",
    "    if fts_mode == \"lfs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"forward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"lbs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"backward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"k-best\": # supervised\n",
    "        # k_best = SelectKBest(chi2, k=nb_fts)\n",
    "        k_best = SelectKBest(f_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "        \n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "    \n",
    "\n",
    "    if fts_mode == \"k-best-mi\": # supervised\n",
    "        k_best = SelectKBest(mutual_info_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    return X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4089ad-f8e9-4e13-8a8a-0185ec66a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def fit_model(X_train_split, y_train_split, X_test_split, y_test_split, model=\"knn\"):\n",
    "    \n",
    "    # 1. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "        \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb06472-c9d5-4011-a3d6-9dc05c174a52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All experiments except Pk-LPNN at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09b4bc-df14-426e-9d0f-5d168b32bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new loop ***\n",
    "# 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_all_d = {}\n",
    "\n",
    "# 1. loop over feat modes:\n",
    "for fts_mode in fts_modes_l:\n",
    "        \n",
    "    results_all_d[fts_mode] = {}\n",
    "\n",
    "    # 2. 10 times 10-fold CV: 100 experiments\n",
    "    for cv_d in tqdm(cv_splits_all):\n",
    "        for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "        \n",
    "            X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p = select_features(train_indices, \n",
    "                                                                                                        test_indices,\n",
    "                                                                                                        data=data,\n",
    "                                                                                                        y=y,\n",
    "                                                                                                        norm=False,\n",
    "                                                                                                        fts_mode=fts_mode)       \n",
    "            # 3. loop over models\n",
    "            for model in models_l:\n",
    "    \n",
    "                if model not in results_all_d[fts_mode].keys():\n",
    "                    results_all_d[fts_mode][model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "                \n",
    "                f1, b_acc = fit_model(X_train_split, \n",
    "                                      y_train_split, \n",
    "                                      X_test_split, \n",
    "                                      y_test_split, \n",
    "                                      model=model)\n",
    "                \n",
    "                results_all_d[fts_mode][model][\"f1\"].append(f1)\n",
    "                results_all_d[fts_mode][model][\"b_acc\"].append(b_acc)\n",
    "                results_all_d[fts_mode][model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    # save all results for fts_mode\n",
    "    for model in models_l:\n",
    "        \n",
    "        with open(os.path.join(results_folder, f\"{fts_mode}_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "            pickle.dump(results_all_d[fts_mode][model], fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb5a3f-67a7-46de-a471-8e35924d4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fts_mode in fts_modes_l:\n",
    "\n",
    "    for model in models_l:\n",
    "        print(\"*\"*60)\n",
    "        \n",
    "        scores_full_fts = results_all_d[fts_mode][model]\n",
    "    \n",
    "        print(f\"*** Features mode: {fts_mode} - Model: {model} ***\")\n",
    "        print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(scores_full_fts[\"f1\"])}\"\"\")\n",
    "        print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(scores_full_fts[\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881f9fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pk-LPNN-selected features (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617088a3-f676-488a-83b9-937d6f86bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 10 times:\n",
    "#   10-fold CV\n",
    "#   train PK-LPNN on 9 folds                     -> Nz selected fts\n",
    "#   test PK-LPNN on 1 fold (KNN + selected fts)  -> b_acc, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ab2116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Security...\n",
    "\n",
    "try:\n",
    "    del X_train_split\n",
    "    del y_train_split\n",
    "    del X_test_split\n",
    "    del y_test_split\n",
    "    del f1\n",
    "    del b_acc\n",
    "    print(\"Variables deleted...\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93a60f-8e5a-42af-a9d6-3294035ddad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPNN_experiment(X_train_split, y_train_split,\n",
    "                    p, Nz, k, mu_0=0.5, train_indices=None):\n",
    "\n",
    "    # 1. normalize (here and not later!)\n",
    "    X_train_split = normalize(X_train_split, axis=0)\n",
    "    \n",
    "    # 2. Initialization\n",
    "    beta_0, mu_0 = beta_0_and_mu_0(p=p, Nz=Nz, k=k, mu_0=mu_0, method=\"Pk-LPNN_v2\")\n",
    "    # check_conditions(beta, X, beta_0, n, Nz, k, method=method)\n",
    "\n",
    "    # 3. dynamical system\n",
    "    z0 = np.hstack([beta_0, mu_0])\n",
    "    t_span = (0, 30) # (0, 30)\n",
    "    t = t_span[1]\n",
    "    eta = Nz\n",
    "\n",
    "    # with tqdm() as pbar: # too much printing\n",
    "        \n",
    "    sol = solve_ivp(LPNN, \n",
    "                    t_span=t_span, \n",
    "                    y0=z0, \n",
    "                    args=(X_train_split, y_train_split, eta, k, \"Pk-LPNN_v2\"), #, pbar),\n",
    "                    method=\"RK45\", # DOP853, RK45\n",
    "                    dense_output=False, \n",
    "                    max_step=0.1, \n",
    "                    atol=1.2e-4, \n",
    "                    rtol=1e-4)\n",
    "\n",
    "    beta_sol = sol[\"y\"][:-1, -1]\n",
    "    mu_sol = sol[\"y\"][-1, -1]\n",
    "\n",
    "    selected_ind = np.argpartition(np.abs(beta_sol), -Nz)[-Nz:]\n",
    "    \n",
    "    return list(selected_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c75e9d-02ef-437b-abde-f4d5f3274b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single experiment for selected features\n",
    "\n",
    "def downstream_models(data=data, y=y, norm=True,\n",
    "               train_indices=None, test_indices=None, selected_ind=None, \n",
    "               model=\"knn\"):\n",
    "    \n",
    "    # 1. fts selection    \n",
    "    current_data = data[:, selected_ind]\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "    y_train_split = 2 * y_train_split - 1                        # rescale targets in {-1, +1}\n",
    "\n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = 2 * y_test_split - 1                          # rescale targets in {-1, +1}\n",
    "\n",
    "    # 3. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "    \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0e91f-9119-49f2-b23b-4006877fbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All experiments: 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_d = {}\n",
    "\n",
    "for i, cv_d in tqdm(enumerate(cv_splits_all)):\n",
    "\n",
    "    for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "            \n",
    "        # train set\n",
    "        X_train_split = data[train_indices, :]\n",
    "        y_train_split = y[train_indices]\n",
    "        y_train_split = 2 * y_train_split - 1        # rescale targets in {-1, +1}\n",
    "\n",
    "        # parameters\n",
    "        k = 1000     # check effect of k\n",
    "        Nz = nb_fts  # i.e. 178 Nz_l[0]\n",
    "        # sigma = 0.02  # useless here, no noise\n",
    "        mu_0 = 0.5\n",
    "\n",
    "        # Pk-LPNN ft selection\n",
    "        selected_ind = LPNN_experiment(X_train_split, y_train_split,\n",
    "                                       p, Nz, k, mu_0=0.5, train_indices=train_indices)\n",
    "        \n",
    "        true_cap_retreived_fts = set(selected_ind).intersection(set(fts_index))\n",
    "        retreived_fts_p = len(true_cap_retreived_fts) / nb_fts\n",
    "                \n",
    "        # model with selected fts\n",
    "        for model in models_l:\n",
    "\n",
    "            if model not in results_d: # create dict if not exists\n",
    "                results_d[model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "            \n",
    "            f1, b_acc = downstream_models(data=data, y=y,\n",
    "                                          norm=False,\n",
    "                                          train_indices=train_indices, \n",
    "                                          test_indices=test_indices, \n",
    "                                          selected_ind=selected_ind, \n",
    "                                          model=model)\n",
    "                        \n",
    "            results_d[model][\"f1\"].append(f1)\n",
    "            results_d[model][\"b_acc\"].append(b_acc)\n",
    "            results_d[model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    print(f\"CV {i+1} finished for all models.\")\n",
    "    \n",
    "\n",
    "# save results\n",
    "for model in models_l:\n",
    "    \n",
    "    with open(os.path.join(results_folder, f\"pk-lpnn_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "        pickle.dump(results_d[model], fh)\n",
    "\n",
    "    print(f\"*** Features mode: Pk-LPNN - Model: {model} ***\")\n",
    "    print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(results_d[model][\"f1\"])}\"\"\")\n",
    "    print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(results_d[model][\"b_acc\"])}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
