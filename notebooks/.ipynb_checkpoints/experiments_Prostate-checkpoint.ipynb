{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fa8ea815",
   "metadata": {},
   "source": [
    "# Genetic Application: Prostate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b0196a-968a-4ce2-94cf-7b1d8d9fb11a",
   "metadata": {},
   "source": [
    "- We consider $n$ samples for **few-shot learning**\n",
    "- The matrix $\\mathbf{X}$ now consists of $n$ samples of size $p = 7129$, with $n << p$.\n",
    "- The vector $\\mathbf{y}$ consists of the $n$ labels of $\\mathbf{X}$ (i.e. $y_i \\in \\{-1, +1\\}$ for all $i = 1,\\dots,n$)\n",
    "- We consider the following **feature selection** task: learn a **sparse set of explainable features** (i.e. pixels) $\\boldsymbol{\\hat \\beta}$ from which a small set of training samples samples $\\mathbf{X}, \\mathbf{y}$ can be classified as gppd as possible. Formally,\n",
    "\n",
    "\\begin{eqnarray}\n",
    "\\text{minimize}_{\\boldsymbol{\\beta} \\in \\mathbb{B}^p} && \\| \\mathbf{X} \\boldsymbol{\\beta} - \\mathbf{y} \\|^2_2 \\\\\n",
    "\\text{subject to} && \\| \\boldsymbol{\\beta} \\|_1 \\leq \\eta\n",
    "\\end{eqnarray}\n",
    "\n",
    "where $\\mathbf{X} \\in \\mathbb{R}^{n \\times p}$ and $\\mathbf{y} \\in \\{-1, +1\\}^{n}$ are the few training samples and labels, respectively (with $n << p$), and $\\eta$ is the number of explainable features to be selected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672002b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c00e25-d4df-4d14-9759-4c8fce74ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplake\n",
    "# !pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89aa8bc-4111-4c3d-93b2-e93eda9aca03",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3737a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "#import deeplake\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, r_regression, chi2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36c0f0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f029b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e0e799-2648-476c-9948-9daf92c37be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prostate_data = fetch_openml(name = 'Prostate', version = 1, as_frame = True, parser = 'auto')\n",
    "data = Prostate_data.data \n",
    "y = Prostate_data.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2076ab-6ff9-4c00-a8df-4502be0eb472",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast data\n",
    "data = np.array(data)  # Conversion de data en numpy array\n",
    "y = np.array(y)        # Conversion de y en numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27debc6-df0d-4501-bbe9-970d6561333b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suffle data\n",
    "np.random.seed(12)\n",
    "\n",
    "indices = np.random.choice(y.shape[0], size=y.shape[0], replace=False)\n",
    "data = data[indices]\n",
    "y = y[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898a558c-55cd-46ae-b0c7-ff4b8efb6f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e78bec4-707e-49a2-b44f-0374c430b1d1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34820472-c35f-4909-8ed5-e17068611436",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_fts = 158    # 1.25%\n",
    "# nb_fts = 315    # 2.50%\n",
    "# b_fts = 630    # 5%\n",
    "nb_fts = 1260   # 10%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abc297-6d64-4d5b-b3ad-b619b58ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = f\"results/genetic_data_Prostate/{nb_fts}\" # separate folder for any nb_fts\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c003bf-99d9-496f-8397-4d48736afac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your models\n",
    "\n",
    "models_l = [\"knn\", \n",
    "            \"lr\", \n",
    "            \"svc\", \n",
    "            \"nb-gaussian\", \n",
    "            ### \"nb-bernouilli\", \n",
    "            ### \"nb-categorical\",\n",
    "            ### \"rf\"\n",
    "           ]\n",
    "\n",
    "# Choose your feature selection methods\n",
    "fts_modes_l = [\"full\", \n",
    "               \"random\", \n",
    "               \"k-best\", \n",
    "               \"k-best-mi\",     # new \n",
    "               ###\"pca\", \n",
    "               \"sparse-pca\", \n",
    "               ###\"lfs\", \n",
    "               ###\"lbs\", \n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d45637-f0ef-4bdd-8917-c1b7a301e335",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ten times 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df87ffb-1eda-4bdd-ae04-00fa6ae75255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_splits(seed=42):\n",
    "\n",
    "    cv_d = {\"train_splits\": [], \"test_splits\": []}\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    kf.get_n_splits(data)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "\n",
    "        cv_d[\"train_splits\"].append(train_index)\n",
    "        cv_d[\"test_splits\"].append(test_index)\n",
    "        \n",
    "    return cv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8feda798-03cb-491f-abf0-d7c53ff788a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_d = get_CV_splits(seed=42)\n",
    "# cv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7060137a-323a-482c-90cf-1fe155f4a79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10 times 10-fold CV\n",
    "\n",
    "cv_splits_all = []\n",
    "\n",
    "for seed in tqdm([33, 42, 1, 5, 1979, 2024, 22, 12, 1996, 11]):\n",
    "    \n",
    "    cv_d = get_CV_splits(seed=seed)\n",
    "    \n",
    "    cv_splits_all.append(cv_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8217b7be-7085-438f-b605-73a309d871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_splits_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4518fa9-7df4-47bf-94fe-dfde9996f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def select_features(train_indices, test_indices, data=data, y=y, norm=True, fts_mode=\"full\"):\n",
    "        \n",
    "    # 2. fts selection\n",
    "    if fts_mode == \"random\":\n",
    "        rand_ind = np.random.randint(low=0, high=data.shape[1], size=nb_fts, dtype=int)\n",
    "        current_data = data[:, rand_ind]\n",
    "        \n",
    "    else:\n",
    "        current_data = data\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_split = label_encoder.fit_transform(y_train_split)\n",
    "    y_train_split = 2 * y_train_split - 1\n",
    "\n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = label_encoder.transform(y_test_split)\n",
    "    y_test_split = 2 * y_test_split - 1\n",
    "\n",
    "    if fts_mode == \"pca\": # unsupervised\n",
    "        pca = PCA(n_components=min(nb_fts, len(X_train_split))) # PCA limited by nb of rows of X (64)\n",
    "        X_train_split = pca.fit_transform(X_train_split)\n",
    "        X_test_split = pca.transform(X_test_split)\n",
    "\n",
    "    if fts_mode == \"sparse-pca\": # unsupervised\n",
    "        sparse_pca = SparsePCA(n_components=nb_fts, alpha=0.5, tol=1e-4, verbose=False)\n",
    "        X_train_split = sparse_pca.fit_transform(X_train_split)\n",
    "        X_test_split = sparse_pca.transform(X_test_split)\n",
    "\n",
    "    if fts_mode == \"lfs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"forward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "    if fts_mode == \"lbs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"backward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "    if fts_mode == \"k-best\": # supervised\n",
    "        # k_best = SelectKBest(chi2, k=nb_fts)\n",
    "        k_best = SelectKBest(f_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split) # no y here!\n",
    "\n",
    "    if fts_mode == \"k-best-mi\": # supervised\n",
    "        k_best = SelectKBest(mutual_info_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split) # no y here!\n",
    "\n",
    "    return X_train_split, y_train_split, X_test_split, y_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4089ad-f8e9-4e13-8a8a-0185ec66a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def fit_model(X_train_split, y_train_split, X_test_split, y_test_split, model=\"knn\"):\n",
    "\n",
    "    # 1. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "        \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb06472-c9d5-4011-a3d6-9dc05c174a52",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## All experiments except Pk-LPNN at once"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56cc1ca3-9655-4f0f-a4d2-eae86313d981",
   "metadata": {},
   "source": [
    "> - The following cell runs all feature selection modes (`fts_modes_l`) and all dowstream models (`models_l`).\n",
    "> \n",
    "> - The results are then saved in `results_folder/`.\n",
    ">\n",
    "> - Hence, the individual sections (Full features, Random features, etc.) do not need to be executed anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc09b4bc-df14-426e-9d0f-5d168b32bf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new loop ***\n",
    "# 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_all_d = {}\n",
    "\n",
    "# 1. loop over feat modes:\n",
    "for fts_mode in fts_modes_l:\n",
    "        \n",
    "    results_all_d[fts_mode] = {}\n",
    "\n",
    "    # 2. 10 times 10-fold CV: 100 experiments\n",
    "    for cv_d in tqdm(cv_splits_all):\n",
    "        for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "        \n",
    "            X_train_split, y_train_split, X_test_split, y_test_split = select_features(train_indices, \n",
    "                                                                                       test_indices,\n",
    "                                                                                       data=data, \n",
    "                                                                                       y=y, \n",
    "                                                                                       norm=True, \n",
    "                                                                                       fts_mode=fts_mode)\n",
    "        \n",
    "        \n",
    "            # 3. loop over models\n",
    "            for model in models_l:\n",
    "    \n",
    "                if model not in results_all_d[fts_mode].keys():\n",
    "                    results_all_d[fts_mode][model] = {\"f1\" : [], \"b_acc\" : []}\n",
    "                \n",
    "                f1, b_acc = fit_model(X_train_split, \n",
    "                                      y_train_split, \n",
    "                                      X_test_split, \n",
    "                                      y_test_split, \n",
    "                                      model=model)\n",
    "                \n",
    "                results_all_d[fts_mode][model][\"f1\"].append(f1)\n",
    "                results_all_d[fts_mode][model][\"b_acc\"].append(b_acc)\n",
    "\n",
    "    # save all results for fts_mode\n",
    "    for model in models_l:\n",
    "        \n",
    "        with open(os.path.join(results_folder, f\"{fts_mode}_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "            pickle.dump(results_all_d[fts_mode][model], fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bb5a3f-67a7-46de-a471-8e35924d4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "for fts_mode in fts_modes_l:\n",
    "\n",
    "    for model in models_l:\n",
    "        print(\"*\"*60)\n",
    "        \n",
    "        scores_full_fts = results_all_d[fts_mode][model]\n",
    "    \n",
    "        print(f\"*** Features mode: {fts_mode} - Model: {model} ***\")\n",
    "        print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(scores_full_fts[\"f1\"])}\"\"\")\n",
    "        print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(scores_full_fts[\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8817b07-aea7-4ee1-9d82-d142e17bb266",
   "metadata": {},
   "source": [
    "> STOP HERE!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881f9fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pk-LPNN-selected features (normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617088a3-f676-488a-83b9-937d6f86bfa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Repeat 10 times:\n",
    "#   10-fold CV\n",
    "#   train PK-LPNN on 9 folds                     -> Nz selected fts\n",
    "#   test PK-LPNN on 1 fold (KNN + selected fts)  -> b_acc, F1-score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff93a60f-8e5a-42af-a9d6-3294035ddad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def LPNN_experiment(p, Nz, k, mu_0=0.5, train_indices=None):\n",
    "\n",
    "    # 1. split\n",
    "    # train set\n",
    "    X = data[train_indices, :]\n",
    "    X = normalize(X, axis=0)\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    Y = y[train_indices]\n",
    "    Y = label_encoder.fit_transform(Y)\n",
    "    Y = 2 * Y - 1\n",
    "\n",
    "    # 2. Initialization\n",
    "    beta_0, mu_0 = beta_0_and_mu_0(p=p, Nz=Nz, k=k, mu_0=mu_0, method=\"Pk-LPNN_v2\")\n",
    "    # check_conditions(beta, X, beta_0, n, Nz, k, method=method)\n",
    "\n",
    "    # 3. dynamical system\n",
    "    z0 = np.hstack([beta_0, mu_0])\n",
    "    t_span = (0, 15) # (0, 300) # here\n",
    "    t = t_span[1]\n",
    "    eta = Nz\n",
    "\n",
    "    # with tqdm() as pbar: # too much printing\n",
    "        \n",
    "    sol = solve_ivp(LPNN, \n",
    "                    t_span=t_span, \n",
    "                    y0=z0, \n",
    "                    args=(X, Y, eta, k, \"Pk-LPNN_v2\"), #, pbar), \n",
    "                    method=\"RK45\", # DOP853, RK45\n",
    "                    dense_output=False, \n",
    "                    max_step=0.1, \n",
    "                    atol=1.2e-4, \n",
    "                    rtol=1e-4)\n",
    "\n",
    "    beta_sol = sol[\"y\"][:-1, -1]\n",
    "    mu_sol = sol[\"y\"][-1, -1]\n",
    "\n",
    "    selected_ind = np.argpartition(np.abs(beta_sol), -Nz)[-Nz:]\n",
    "    \n",
    "    return list(selected_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c75e9d-02ef-437b-abde-f4d5f3274b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# single experiment for selected features\n",
    "\n",
    "def experiment(cv_d, data=data, y=y, norm=True, \n",
    "               train_indices=None, test_indices=None, selected_ind=None, \n",
    "               model=\"knn\"):\n",
    "    \n",
    "    # 1. fts selection    \n",
    "    current_data = data[:, selected_ind]\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_split = label_encoder.fit_transform(y_train_split)\n",
    "    y_train_split = 2 * y_train_split - 1\n",
    "\n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = label_encoder.transform(y_test_split)\n",
    "    y_test_split = 2 * y_test_split - 1\n",
    "\n",
    "    # 3. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "    \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae0e91f-9119-49f2-b23b-4006877fbcd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# All experiments: 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_d = {}\n",
    "\n",
    "for i, cv_d in tqdm(enumerate(cv_splits_all)):\n",
    "\n",
    "    for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "        # train set\n",
    "        X_train_split = data[train_indices, :]\n",
    "        y_train_split = y[train_indices]\n",
    "\n",
    "        # parameters\n",
    "        n = X_train_split.shape[0]\n",
    "        p = X_train_split.shape[1]\n",
    "        k = 1000\n",
    "        # Nz_l = [int(X_train_split.shape[1] / 40)] # [100] # [20] # [150] # [100, 150, 200] # xxx useless now\n",
    "        # eta_l = Nz_l                                                                       # xxx useless now\n",
    "        # eta_l = eta_l[0]                                                                   # xxx useless now\n",
    "        Nz = nb_fts # i.e. 178 Nz_l[0]\n",
    "        # sigma = 0.02  # useless here, no noise\n",
    "        mu_0 = 0.5\n",
    "\n",
    "        # Pk-LPNN ft selection\n",
    "        selected_ind = LPNN_experiment(p, Nz, k, mu_0=0.5, train_indices=train_indices)\n",
    "        # print(\"selected_ind\", selected_ind)\n",
    "        \n",
    "        # model with selected fts\n",
    "        for model in models_l:\n",
    "\n",
    "            if model not in results_d: # create dict if not exists\n",
    "                results_d[model] = {\"f1\" : [], \"b_acc\" : []}\n",
    "            \n",
    "            f1, b_acc = experiment(cv_d, data=data, y=y, norm=True, \n",
    "                                   train_indices=train_indices, test_indices=test_indices, \n",
    "                                   selected_ind=selected_ind, model=model)\n",
    "    \n",
    "            results_d[model][\"f1\"].append(f1)\n",
    "            results_d[model][\"b_acc\"].append(b_acc)\n",
    "\n",
    "    print(f\"CV {i+1} finished for all models.\")\n",
    "    \n",
    "\n",
    "# save results\n",
    "for model in models_l:\n",
    "    \n",
    "    with open(os.path.join(results_folder, f\"pk-lpnn_{nb_fts}_{model}.pkl\"), \"wb\") as fh: # xxx\n",
    "        pickle.dump(results_d[model], fh)\n",
    "\n",
    "    print(f\"*** Features mode: Pk-LPNN - Model: {model} ***\")\n",
    "    print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(results_d[model][\"f1\"])}\"\"\")\n",
    "    print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(results_d[model][\"b_acc\"])}\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
