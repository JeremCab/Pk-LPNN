{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "31a4484c",
   "metadata": {
    "raw_mimetype": "text/x-python",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# ***       Parameters cell        ***\n",
    "# *** Used to automate experiments ***\n",
    "\n",
    "# View > Cell Toolbar > Tags: set the tag as \"parameters\"\n",
    "\n",
    "p = 4000                  # 2000  # Default value\n",
    "n_ = 10                   #  10   # Default value # Not the real n! Real n defined below...\n",
    "percent_relevent = 4.25   # 3, 5  # Defalut value\n",
    "percent = 2.5             # 2.5  # Default value (varying)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429d8045",
   "metadata": {},
   "source": [
    "# Genetic Application: Synthetic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672002b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "80c00e25-d4df-4d14-9759-4c8fce74ae9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install deeplake\n",
    "# !pip install -U scikit-learn\n",
    "\n",
    "# # --- For automated experiments --- #\n",
    "# !pip install papermill\n",
    "# !pip install jupyter_contrib_nbextensions\n",
    "# !jupyter contrib nbextension install --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "b7fd1fb7-0f9c-44e8-a1a3-9fd4cf718dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "3737a25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import pickle\n",
    "\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.io\n",
    "\n",
    "#import deeplake\n",
    "import sklearn\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.feature_selection import SequentialFeatureSelector, SelectKBest\n",
    "from sklearn.feature_selection import f_classif, mutual_info_classif, r_regression, chi2\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.decomposition import PCA, SparsePCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB, CategoricalNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "from src.utils import *\n",
    "from src.models import *\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d36c0f0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f029b1",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ace7767a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The parameters cell must be the first cell of the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5a46513c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** Data ***\n",
      "Number features p:\t\t\t 4000\n",
      "Number of observations n:\t\t 400\n",
      "Number of relevant features n_relevant:\t 170\n",
      "*** Model ***\n",
      "Number of selected features N_z:\t 100\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "\n",
    "n =  p // n_    # redefine n\n",
    "nb_fts = int(p * percent // 100)\n",
    "n_relevant = int((percent_relevent / 100) * p)\n",
    "\n",
    "print(\"*** Data ***\")\n",
    "print(f\"Number features p:\\t\\t\\t {p}\")\n",
    "print(f\"Number of observations n:\\t\\t {n}\")\n",
    "print(f\"Number of relevant features n_relevant:\\t {n_relevant}\")\n",
    "\n",
    "print(\"*** Model ***\")\n",
    "print(f\"Number of selected features N_z:\\t {nb_fts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e2abc297-6d64-4d5b-b3ad-b619b58ef699",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder = os.path.join( f\"../results/Synthetic/synthetic_data_{p}\" ) # separate folders for different p\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "\n",
    "results_folder = os.path.join( results_folder, f\"{n}\" )       # separate folders for different n\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)\n",
    "    \n",
    "results_folder = os.path.join( results_folder, f\"{nb_fts}\" )  # separate folders for different nb_fts\n",
    "\n",
    "if not os.path.exists(results_folder):\n",
    "    os.mkdir(results_folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f85ff1f3-afb1-43c3-917b-2218ac1cbca4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Models and Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1c7b5c51-7a22-4ce9-8392-37225718479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose your models\n",
    "\n",
    "models_l = [\"knn\", \n",
    "            \"lr\", \n",
    "            \"svc\", \n",
    "            \"nb-gaussian\", \n",
    "            ### \"nb-bernouilli\", \n",
    "            ### \"nb-categorical\",\n",
    "            ### \"rf\"\n",
    "           ]\n",
    "\n",
    "# Choose your feature selection methods\n",
    "fts_modes_l = [#\"full\", \n",
    "               #\"random\", \n",
    "               #\"k-best\", \n",
    "               \"k-best-mi\",\n",
    "               #\"lasso\",\n",
    "               ###\"pca\", \n",
    "               # \"sparse-pca\",  # takes huge time...\n",
    "               ###\"lfs\", \n",
    "               ###\"lbs\", \n",
    "              ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ef7817-1f26-4d4b-ba7d-f45ebc2e21f8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4ed20e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_features = p             # Total number of features\n",
    "n_observations = n         # Number of samples (rows)\n",
    "n_important = n_relevant  # Number of informative (relevant) features\n",
    "fts_index = None\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a1490b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_classification_data(n, n_important, n_features):\n",
    "    \n",
    "    # Step 1: Generate the matrix of relevant features (random normal values)\n",
    "    important_features = np.random.randn(n, n_important)              # Values from a normal distribution\n",
    "\n",
    "    # Step 2: Generate redundant features (random linear combinations of relevant features)\n",
    "    weights = np.random.randn(n_important, n_features - n_important)  # Random weights\n",
    "    redundant_features = np.dot(important_features, weights)          # Random linear combinations\n",
    "\n",
    "    # Step 3: Combine relevant and redundant features\n",
    "    full_matrix = np.hstack((important_features, redundant_features)) # Concatenate horizontally\n",
    "\n",
    "    # Step 4: Randomly shuffle the order of columns to disperse relevant features\n",
    "    column_order = np.random.permutation(n_features)                  # Uniform random permutation\n",
    "    data = full_matrix[:, column_order]                               # Apply shuffled order\n",
    "\n",
    "    # Step 5: Generate a random model for binary classification\n",
    "    random_vector = np.random.randn(n_important, 1)                   # Random vector from normal distribution\n",
    "    scores = np.dot(important_features, random_vector)                # Compute scores\n",
    "\n",
    "    # Classify: Positive scores as 1, negative scores as 0\n",
    "    class_labels = np.ones(n)  # Initialize all to 1\n",
    "    class_labels[scores.flatten() < np.mean(scores)] = 0              # Assign 0 for scores below the mean\n",
    "\n",
    "    # Step 6: Verify properties\n",
    "    rank_important = np.linalg.matrix_rank(important_features)        # Rank of relevant features matrix\n",
    "    print(f\"Rank of important features matrix:\\t {rank_important}\")\n",
    "\n",
    "    # Display dimensions\n",
    "    print(f\"Size of full features matrix:\\t\\t {data.shape}\")\n",
    "\n",
    "    return data, class_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "acefe069",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank of important features matrix:\t 92\n",
      "Size of full features matrix:\t\t (200, 2000)\n"
     ]
    }
   ],
   "source": [
    "data, class_labels = generate_classification_data(n=n, n_important=n_relevant, n_features=p)\n",
    "# print(\"Classification labels:\")\n",
    "# print(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "09c4e855",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 2000), (200,))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = class_labels # new\n",
    "data.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f9fa7a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(92)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.matrix_rank(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d45637-f0ef-4bdd-8917-c1b7a301e335",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Ten times 10-fold cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2df87ffb-1eda-4bdd-ae04-00fa6ae75255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CV_splits(data=data, seed=42):\n",
    "\n",
    "    cv_d = {\"train_splits\": [], \"test_splits\": []}\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "    kf.get_n_splits(data)\n",
    "\n",
    "    for train_index, test_index in kf.split(data):\n",
    "\n",
    "        cv_d[\"train_splits\"].append(train_index)\n",
    "        cv_d[\"test_splits\"].append(test_index)\n",
    "        \n",
    "    return cv_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8feda798-03cb-491f-abf0-d7c53ff788a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_d = get_CV_splits(data=data, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7060137a-323a-482c-90cf-1fe155f4a79e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [00:00<00:00, 2538.31it/s]\n"
     ]
    }
   ],
   "source": [
    "# 10 times 10-fold CV\n",
    "\n",
    "cv_splits_all = []\n",
    "\n",
    "for seed in tqdm([33, 42, 1, 5, 1979, 2024, 22, 12, 1996, 11]):\n",
    "    \n",
    "    cv_d = get_CV_splits(data, seed=seed)\n",
    "    \n",
    "    cv_splits_all.append(cv_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8217b7be-7085-438f-b605-73a309d871f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv_splits_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d4518fa9-7df4-47bf-94fe-dfde9996f467",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def select_features(train_indices, test_indices, data=data, y=y, \n",
    "                    norm=True, fts_mode=\"full\", fts_index=fts_index):\n",
    "\n",
    "    # 2. fts selection\n",
    "    if fts_mode == \"random\":\n",
    "        rand_ind = np.random.randint(low=0, high=data.shape[1], size=nb_fts, dtype=int)\n",
    "        current_data = data[:, rand_ind]\n",
    "\n",
    "        # # percentage of retreiveed features\n",
    "        # intersection = set(rand_ind).intersection(set(fts_index))\n",
    "        # retreived_fts_p = len(intersection) / len(fts_index)\n",
    "        retreived_fts_p = 0.\n",
    "\n",
    "    else:\n",
    "        current_data = data\n",
    "        retreived_fts_p = 0.  # dummy value for \"full\" mode\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_train_split = label_encoder.fit_transform(y_train_split)\n",
    "    y_train_split = 2 * y_train_split - 1               # rescale targets in {-1, +1}\n",
    "    \n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = label_encoder.transform(y_test_split)\n",
    "    y_test_split = 2 * y_test_split - 1                 # rescale targets in {-1, +1}\n",
    "    \n",
    "    if fts_mode == \"lasso\": # supervised\n",
    "        lasso = Lasso(alpha=1)\n",
    "        lasso.fit(X_train_split, y_train_split)\n",
    "        coeffs = lasso.coef_[lasso.coef_ != 0]\n",
    "        coeffs = np.abs(coeffs)\n",
    "        coeffs = np.sort(coeffs)[-nb_fts:]\n",
    "        lasso_idx = np.argwhere(np.abs(lasso.coef_) >= coeffs[0]).reshape(-1)\n",
    "        X_train_split = X_train_split[:, lasso_idx]\n",
    "        X_test_split = X_test_split[:, lasso_idx]\n",
    "    \n",
    "    if fts_mode == \"pca\": # unsupervised\n",
    "        pca = PCA(n_components=min(nb_fts, len(X_train_split))) # PCA limited by nb of rows of X (64)\n",
    "        X_train_split = pca.fit_transform(X_train_split)\n",
    "        X_test_split = pca.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"sparse-pca\": # unsupervised\n",
    "        sparse_pca = SparsePCA(n_components=nb_fts, alpha=0.5, tol=1e-4, verbose=False)\n",
    "        X_train_split = sparse_pca.fit_transform(X_train_split)\n",
    "        X_test_split = sparse_pca.transform(X_test_split)\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(sparse_pca, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index) # new\n",
    "\n",
    "        retreived_fts_p = 0.\n",
    "\n",
    "\n",
    "    if fts_mode == \"lfs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"forward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"lbs\": # supervised\n",
    "        # Note that the model used in the LFS algo and the downstream classifier (current_model) are the same!\n",
    "        lfs = SequentialFeatureSelector(current_model, n_features_to_select=nb_fts, direction=\"backward\")\n",
    "        X_train_split = lfs.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = lfs.transform(X_test_split)\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    if fts_mode == \"k-best\": # supervised\n",
    "        # k_best = SelectKBest(chi2, k=nb_fts)\n",
    "        k_best = SelectKBest(f_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "        \n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "    \n",
    "\n",
    "    if fts_mode == \"k-best-mi\": # supervised\n",
    "        k_best = SelectKBest(mutual_info_classif, k=nb_fts)\n",
    "        X_train_split = k_best.fit_transform(X_train_split, y_train_split)\n",
    "        X_test_split = k_best.transform(X_test_split)  # no y here!\n",
    "\n",
    "#         retreived_fts_p = get_percentage_retreived_fts(k_best, \n",
    "#                                                        X_train_split, \n",
    "#                                                        y_train_split, \n",
    "#                                                        fts_index)  # new\n",
    "\n",
    "        retreived_fts_p = 0.  # to be implemented if needed\n",
    "\n",
    "    return X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0c4089ad-f8e9-4e13-8a8a-0185ec66a244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# *** new function ***\n",
    "def fit_model(X_train_split, y_train_split, X_test_split, y_test_split, model=\"knn\"):\n",
    "    \n",
    "    # 1. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "        \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb06472-c9d5-4011-a3d6-9dc05c174a52",
   "metadata": {},
   "source": [
    "## All experiments except Pk-LPNN at once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc09b4bc-df14-426e-9d0f-5d168b32bf93",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████| 10/10 [02:06<00:00, 12.61s/it]\n"
     ]
    }
   ],
   "source": [
    "# *** new loop ***\n",
    "# 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_all_d = {}\n",
    "\n",
    "# 1. loop over feat modes:\n",
    "for fts_mode in fts_modes_l:\n",
    "        \n",
    "    results_all_d[fts_mode] = {}\n",
    "\n",
    "    # 2. 10 times 10-fold CV: 100 experiments\n",
    "    for cv_d in tqdm(cv_splits_all):\n",
    "        for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "        \n",
    "            X_train_split, y_train_split, X_test_split, y_test_split, retreived_fts_p = select_features(train_indices, \n",
    "                                                                                                        test_indices,\n",
    "                                                                                                        data=data,\n",
    "                                                                                                        y=y,\n",
    "                                                                                                        norm=False, # drastically influences the results\n",
    "                                                                                                        fts_mode=fts_mode)       \n",
    "            # 3. loop over models\n",
    "            for model in models_l:\n",
    "    \n",
    "                if model not in results_all_d[fts_mode].keys():\n",
    "                    results_all_d[fts_mode][model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "                \n",
    "                f1, b_acc = fit_model(X_train_split, \n",
    "                                      y_train_split, \n",
    "                                      X_test_split, \n",
    "                                      y_test_split, \n",
    "                                      model=model)\n",
    "                \n",
    "                results_all_d[fts_mode][model][\"f1\"].append(f1)\n",
    "                results_all_d[fts_mode][model][\"b_acc\"].append(b_acc)\n",
    "                results_all_d[fts_mode][model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    # save all results for fts_mode\n",
    "    for model in models_l:\n",
    "        \n",
    "        with open(os.path.join(results_folder, f\"{fts_mode}_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "            pickle.dump(results_all_d[fts_mode][model], fh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "16bb5a3f-67a7-46de-a471-8e35924d4835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "*** Features mode: k-best-mi - Model: knn ***\n",
      "Test: macro F1 (mean, std): \t\t0.6075088902421618\n",
      "Test: balanced accuracy (mean, std): \t0.6261535894660895\n",
      "************************************************************\n",
      "*** Features mode: k-best-mi - Model: lr ***\n",
      "Test: macro F1 (mean, std): \t\t0.730252374076252\n",
      "Test: balanced accuracy (mean, std): \t0.7435655108780108\n",
      "************************************************************\n",
      "*** Features mode: k-best-mi - Model: svc ***\n",
      "Test: macro F1 (mean, std): \t\t0.7201975318610995\n",
      "Test: balanced accuracy (mean, std): \t0.7338317654567654\n",
      "************************************************************\n",
      "*** Features mode: k-best-mi - Model: nb-gaussian ***\n",
      "Test: macro F1 (mean, std): \t\t0.6819348656133354\n",
      "Test: balanced accuracy (mean, std): \t0.6946626845376846\n"
     ]
    }
   ],
   "source": [
    "for fts_mode in fts_modes_l:\n",
    "\n",
    "    for model in models_l:\n",
    "        print(\"*\"*60)\n",
    "        \n",
    "        scores_full_fts = results_all_d[fts_mode][model]\n",
    "    \n",
    "        print(f\"*** Features mode: {fts_mode} - Model: {model} ***\")\n",
    "        print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(scores_full_fts[\"f1\"])}\"\"\")\n",
    "        print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(scores_full_fts[\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "48a02067-9915-438f-82cd-df7408c68c17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiments finished.\n"
     ]
    }
   ],
   "source": [
    "# Break here to avoid Pk-LPNN experiments\n",
    "# Comment for running all experiments\n",
    "print(\"Experiments finished.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0881f9fb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Pk-LPNN-selected features (normalized)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1d0c6dac-50f1-4e12-af81-65d49c2b4c77",
   "metadata": {},
   "source": [
    "# Repeat 10 times:\n",
    "#   10-fold CV\n",
    "#   train PK-LPNN on 9 folds                     -> Nz selected fts\n",
    "#   test PK-LPNN on 1 fold (KNN + selected fts)  -> b_acc, F1-score"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ed55aede-2667-41ca-a7ce-135df9645e04",
   "metadata": {},
   "source": [
    "# Security...\n",
    "\n",
    "try:\n",
    "    del X_train_split\n",
    "    del y_train_split\n",
    "    del X_test_split\n",
    "    del y_test_split\n",
    "    del f1\n",
    "    del b_acc\n",
    "    print(\"Variables deleted...\")\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "raw",
   "id": "61b39f89-c330-4f7d-a2e8-2d5908180c9d",
   "metadata": {},
   "source": [
    "def LPNN_experiment(X_train_split, y_train_split,\n",
    "                    p, Nz, k, mu_0=0.5, train_indices=None):\n",
    "\n",
    "    # 1. normalize (here and not later!)\n",
    "    X_train_split = normalize(X_train_split, axis=0)\n",
    "    \n",
    "    # 2. Initialization\n",
    "    beta_0, mu_0 = beta_0_and_mu_0(p=p, Nz=Nz, k=k, mu_0=mu_0, method=\"Pk-LPNN_v2\")\n",
    "    # check_conditions(beta, X, beta_0, n, Nz, k, method=method)\n",
    "\n",
    "    # 3. dynamical system\n",
    "    z0 = np.hstack([beta_0, mu_0])\n",
    "    t_span = (0, 30) # (0, 30)\n",
    "    t = t_span[1]\n",
    "    eta = Nz\n",
    "\n",
    "    # with tqdm() as pbar: # too much printing\n",
    "        \n",
    "    sol = solve_ivp(LPNN, \n",
    "                    t_span=t_span, \n",
    "                    y0=z0, \n",
    "                    args=(X_train_split, y_train_split, eta, k, \"Pk-LPNN_v2\"), #, pbar),\n",
    "                    method=\"RK45\", # DOP853, RK45\n",
    "                    dense_output=False, \n",
    "                    max_step=0.1, \n",
    "                    atol=1.2e-4, \n",
    "                    rtol=1e-4)\n",
    "\n",
    "    beta_sol = sol[\"y\"][:-1, -1]\n",
    "    mu_sol = sol[\"y\"][-1, -1]\n",
    "\n",
    "    selected_ind = np.argpartition(np.abs(beta_sol), -Nz)[-Nz:]\n",
    "    \n",
    "    return list(selected_ind)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "28024d9a-add1-4339-810e-c0792ad9ea23",
   "metadata": {},
   "source": [
    "# single experiment for selected features\n",
    "\n",
    "def downstream_models(data=data, y=y, norm=True,\n",
    "               train_indices=None, test_indices=None, selected_ind=None, \n",
    "               model=\"knn\"):\n",
    "    \n",
    "    # 1. fts selection    \n",
    "    current_data = data[:, selected_ind]\n",
    "\n",
    "    # 2. split\n",
    "    # train set\n",
    "    X_train_split = current_data[train_indices, :]\n",
    "    if norm:\n",
    "        X_train_split = normalize(X_train_split, axis=0)\n",
    "    y_train_split = y[train_indices]\n",
    "    y_train_split = 2 * y_train_split - 1                        # rescale targets in {-1, +1}\n",
    "\n",
    "    # test set\n",
    "    X_test_split = current_data[test_indices, :]\n",
    "    if norm:\n",
    "        X_test_split = normalize(X_test_split, axis=0)\n",
    "    y_test_split = y[test_indices]\n",
    "    y_test_split = 2 * y_test_split - 1                          # rescale targets in {-1, +1}\n",
    "\n",
    "    # 3. model\n",
    "    if model == \"knn\":\n",
    "        current_model = KNeighborsClassifier()\n",
    "    elif model == \"lr\":\n",
    "        current_model = LogisticRegression()\n",
    "    elif model == \"svc\":\n",
    "        current_model = SVC()\n",
    "    elif model == \"nb-gaussian\":\n",
    "        current_model = GaussianNB()\n",
    "    elif model == \"nb-complement\":\n",
    "        current_model = ComplementNB()\n",
    "    elif model == \"nb-bernouilli\":\n",
    "        current_model = BernoulliNB()\n",
    "    elif model == \"nb-categorical\":\n",
    "        current_model = CategoricalNB()\n",
    "    elif model == \"rf\":\n",
    "        current_model = RandomForestClassifier()\n",
    "    \n",
    "    current_model.fit(X_train_split, y_train_split)\n",
    "    y_test_preds = current_model.predict(X_test_split)\n",
    "\n",
    "    # results\n",
    "    # report = classification_report(y_test_split, y_test_preds)\n",
    "    f1 = f1_score(y_test_split, y_test_preds, average='macro')\n",
    "    b_acc = balanced_accuracy_score(y_test_split, y_test_preds)\n",
    "    \n",
    "    return f1, b_acc"
   ]
  },
  {
   "cell_type": "raw",
   "id": "10ba288b-98a8-4b74-8f8d-2cb99b860f30",
   "metadata": {},
   "source": [
    "# All experiments: 10 times 10-fold CV: 100 experiments\n",
    "\n",
    "results_d = {}\n",
    "\n",
    "for i, cv_d in tqdm(enumerate(cv_splits_all)):\n",
    "\n",
    "    for train_indices, test_indices in zip(cv_d[\"train_splits\"], cv_d[\"test_splits\"]):\n",
    "            \n",
    "        # train set\n",
    "        X_train_split = data[train_indices, :]\n",
    "        y_train_split = y[train_indices]\n",
    "        y_train_split = 2 * y_train_split - 1        # rescale targets in {-1, +1}\n",
    "\n",
    "        # parameters\n",
    "        k = 1000     # check effect of k\n",
    "        Nz = nb_fts  # i.e. 178 Nz_l[0]\n",
    "        # sigma = 0.02  # useless here, no noise\n",
    "        mu_0 = 0.5\n",
    "\n",
    "        # Pk-LPNN ft selection\n",
    "        np.random.seed(42)\n",
    "        selected_ind = LPNN_experiment(X_train_split, y_train_split,\n",
    "                                       p, Nz, k, mu_0=0.5, train_indices=train_indices)\n",
    "        \n",
    "        try:\n",
    "            true_cap_retreived_fts = set(selected_ind).intersection(set(fts_index))\n",
    "            retreived_fts_p = len(true_cap_retreived_fts) / nb_fts\n",
    "        except:\n",
    "            retreived_fts_p = None\n",
    "        \n",
    "        # model with selected fts\n",
    "        for model in models_l:\n",
    "\n",
    "            if model not in results_d: # create dict if not exists\n",
    "                results_d[model] = {\"f1\" : [], \"b_acc\" : [], \"retreived_fts_p\" : []}\n",
    "            \n",
    "            f1, b_acc = downstream_models(data=data, y=y,\n",
    "                                          norm=False,\n",
    "                                          train_indices=train_indices, \n",
    "                                          test_indices=test_indices, \n",
    "                                          selected_ind=selected_ind, \n",
    "                                          model=model)\n",
    "                        \n",
    "            results_d[model][\"f1\"].append(f1)\n",
    "            results_d[model][\"b_acc\"].append(b_acc)\n",
    "            results_d[model][\"retreived_fts_p\"].append(retreived_fts_p)\n",
    "\n",
    "    print(f\"CV {i+1} finished for all models.\")\n",
    "    \n",
    "\n",
    "# save results\n",
    "for model in models_l:\n",
    "    \n",
    "    with open(os.path.join(results_folder, f\"pk-lpnn_{nb_fts}_{model}.pkl\"), \"wb\") as fh:\n",
    "        pickle.dump(results_d[model], fh)\n",
    "\n",
    "    print(f\"*** Features mode: Pk-LPNN - Model: {model} ***\")\n",
    "    print(f\"\"\"Test: macro F1 (mean, std): \\t\\t{np.mean(results_d[model][\"f1\"])}\"\"\")\n",
    "    print(f\"\"\"Test: balanced accuracy (mean, std): \\t{np.mean(results_d[model][\"b_acc\"])}\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b61e29",
   "metadata": {},
   "source": [
    "**Remark**\n",
    "- Use $N_z \\in \\{ 0.75\\%, 1.00\\%, 1.25\\% \\}$ et $n \\simeq N_z \\cdot \\log(\\frac{p}{N_z})$"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python (.venv)",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
